# Confiture Development Guide

**Project**: Confiture - PostgreSQL Migrations, Sweetly Done üçì
**Version**: 0.5.0
**Last Updated**: January 2026
**Current Status**: Feature Complete (Beta)

---

## üéØ Project Overview

**Confiture** is a modern PostgreSQL migration tool for Python with a **build-from-scratch philosophy** and **4 migration strategies**. This document guides AI-assisted development.

### Core Philosophy

> **"Build from DDL, not migration history"**

The `db/schema/` directory is the **single source of truth**. Migrations are derived, not primary.

### The Four Mediums

1. **Build from DDL** (`confiture build`) - Fresh databases in <1s
2. **Incremental Migrations** (`confiture migrate up`) - ALTER for simple changes
3. **Production Sync** (`confiture sync`) - Copy data with anonymization
4. **Schema-to-Schema** (`confiture migrate schema-to-schema`) - Zero-downtime via FDW

---

## üìö Essential Reading

Before coding, read these documents in order:

1. **[PRD.md](./PRD.md)** - Product requirements, user stories, success metrics
2. **[ARCHITECTURE.md](./ARCHITECTURE.md)** - Technical architecture and design decisions
3. **[docs/](./docs/)** - User guides and API documentation

---

## üèóÔ∏è Development Methodology

### TDD Approach

Confiture follows **disciplined TDD cycles**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TDD CYCLE                            ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ   RED   ‚îÇ‚îÄ‚ñ∂‚îÇ GREEN   ‚îÇ‚îÄ‚ñ∂‚îÇ  REFACTOR   ‚îÇ‚îÄ‚ñ∂‚îÇ   QA    ‚îÇ ‚îÇ
‚îÇ ‚îÇ Failing ‚îÇ  ‚îÇ Minimal ‚îÇ  ‚îÇ Clean &     ‚îÇ  ‚îÇ Verify  ‚îÇ ‚îÇ
‚îÇ ‚îÇ Test    ‚îÇ  ‚îÇ Code    ‚îÇ  ‚îÇ Optimize    ‚îÇ  ‚îÇ Quality ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### TDD Discipline

**RED**: Write specific failing test
```bash
uv run pytest tests/unit/test_builder.py::test_build_schema_local -v
# Expected: FAILED (not implemented yet)
```

**GREEN**: Minimal implementation to pass
```bash
uv run pytest tests/unit/test_builder.py::test_build_schema_local -v
# Expected: PASSED (minimal working code)
```

**REFACTOR**: Clean up, optimize
```bash
uv run pytest tests/unit/test_builder.py -v
# All tests still pass after refactoring
```

**QA**: Full validation
```bash
uv run pytest --cov=confiture --cov-report=term-missing
uv run ruff check .
uv run mypy confiture/
```

---

## üõ†Ô∏è Technology Stack

### Core Dependencies

```toml
# pyproject.toml dependencies
[project.dependencies]
python = ">=3.11"
typer = ">=0.12"          # CLI framework
pydantic = ">=2.0"        # Configuration validation
pyyaml = ">=6.0"          # YAML parsing
psycopg = {version = ">=3.0", extras = ["binary"]}  # PostgreSQL driver
rich = ">=13.0"           # Terminal formatting
sqlparse = ">=0.5"        # SQL parsing (Python)

[project.optional-dependencies]
dev = [
    "pytest>=8.0",
    "pytest-asyncio>=0.23",
    "pytest-cov>=4.1",
    "ruff>=0.6",
    "mypy>=1.11",
    "pre-commit>=3.0",
]
```

### Rust Extension (Optional Performance)

Confiture includes an optional Rust extension for improved performance:

```toml
# Cargo.toml
[dependencies]
pyo3 = "0.22"             # Python bindings
sqlparser = "0.52"        # SQL parsing (Rust)
tokio = "1"               # Async runtime
tokio-postgres = "0.7"    # PostgreSQL driver
sha2 = "0.10"             # Hashing
```

---

## üìÅ Project Structure

```
confiture/
‚îú‚îÄ‚îÄ python/confiture/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py              # Public API
‚îÇ   ‚îú‚îÄ‚îÄ cli/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Entry point (Typer app)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ build.py             # confiture build
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ migrate.py           # confiture migrate
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sync.py              # confiture sync
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ builder.py           # Schema builder (Medium 1)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ migrator.py          # Migration executor (Medium 2)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ differ.py            # Schema diff detector
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ syncer.py            # Production sync (Medium 3)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schema_to_schema.py  # FDW migration (Medium 4)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ environment.py       # Environment config
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ version.py           # Version tracking
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ migration.py         # Migration base class
‚îÇ       ‚îî‚îÄ‚îÄ schema.py            # Schema models
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/                    # Fast, isolated tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_builder.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_migrator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_differ.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_config.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ integration/             # Database-dependent tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_build_local.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_migrate_up.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_sync.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ e2e/                     # Full workflow tests
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_complete_workflow.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ fixtures/                # Test data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ migrations/
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py              # Pytest config
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ index.md                 # Documentation homepage
‚îÇ   ‚îú‚îÄ‚îÄ getting-started.md
‚îÇ   ‚îú‚îÄ‚îÄ guides/                 # User guides
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medium-1-build-from-ddl.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medium-2-incremental-migrations.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medium-3-production-sync.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medium-4-schema-to-schema.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ migration-decision-tree.md
‚îÇ   ‚îú‚îÄ‚îÄ reference/              # API/CLI reference
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cli.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ configuration.md
‚îÇ   ‚îî‚îÄ‚îÄ api/                    # API documentation
‚îÇ       ‚îú‚îÄ‚îÄ builder.md
‚îÇ       ‚îú‚îÄ‚îÄ migrator.md
‚îÇ       ‚îú‚îÄ‚îÄ syncer.md
‚îÇ       ‚îî‚îÄ‚îÄ schema-to-schema.md
‚îÇ
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ basic/                   # Simple example
‚îÇ   ‚îú‚îÄ‚îÄ fraiseql/                # FraiseQL integration
‚îÇ   ‚îî‚îÄ‚îÄ zero-downtime/           # Production migration
‚îÇ
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ ci.yml               # Run tests
‚îÇ       ‚îî‚îÄ‚îÄ release.yml          # Build wheels
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml               # Python packaging
‚îú‚îÄ‚îÄ uv.lock                      # Dependency lock file
‚îú‚îÄ‚îÄ .python-version              # Python 3.11
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ PRD.md
‚îú‚îÄ‚îÄ CLAUDE.md                    # This file
‚îú‚îÄ‚îÄ PHASES.md
‚îî‚îÄ‚îÄ LICENSE
```

---

## üß™ Testing Strategy

### Test Pyramid

```
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ     E2E     ‚îÇ  10% - Full workflows
        ‚îÇ   (slow)    ‚îÇ
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
        ‚îÇ Integration ‚îÇ  30% - Database operations
        ‚îÇ  (medium)   ‚îÇ
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
        ‚îÇ    Unit     ‚îÇ  60% - Fast, isolated
        ‚îÇ   (fast)    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Test Categories

**Unit Tests** (60% of tests):
```python
# tests/unit/test_builder.py
def test_find_sql_files():
    """Test file discovery without database"""
    builder = SchemaBuilder(env="test")
    files = builder.find_sql_files()
    assert len(files) > 0
    assert all(f.suffix == ".sql" for f in files)
```

**Integration Tests** (30% of tests):
```python
# tests/integration/test_build_local.py
@pytest.mark.asyncio
async def test_build_creates_database(test_db):
    """Test actual database creation"""
    builder = SchemaBuilder(env="test")
    await builder.build()

    # Verify tables exist
    async with test_db.connection() as conn:
        result = await conn.execute("SELECT COUNT(*) FROM pg_tables WHERE schemaname = 'public'")
        assert result.scalar() > 0
```

**E2E Tests** (10% of tests):
```python
# tests/e2e/test_complete_workflow.py
def test_full_migration_cycle():
    """Test: init -> build -> migrate -> verify"""
    runner = CliRunner()

    # Initialize
    result = runner.invoke(cli, ["init"])
    assert result.exit_code == 0

    # Build
    result = runner.invoke(cli, ["build", "--env", "test"])
    assert result.exit_code == 0

    # Migrate
    result = runner.invoke(cli, ["migrate", "up"])
    assert result.exit_code == 0
```

### Running Tests

```bash
# All tests
uv run pytest

# Unit tests only (fast)
uv run pytest tests/unit/ -v

# Integration tests (requires PostgreSQL)
uv run pytest tests/integration/ -v

# With coverage
uv run pytest --cov=confiture --cov-report=html

# Watch mode (during development)
uv run pytest-watch

# Specific test
uv run pytest tests/unit/test_builder.py::test_find_sql_files -v
```

---

## üöÄ Development Workflow

### Setting Up

```bash
# Clone repository
git clone https://github.com/evoludigit/confiture.git
cd confiture

# Install uv (if not installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create virtual environment and install dependencies
uv sync --all-extras

# Install pre-commit hooks
uv run pre-commit install

# Verify installation
uv run confiture --version
```

### Daily Development

```bash
# 1. Create feature branch
git checkout -b feature/schema-diff

# 2. Write failing test (RED)
vim tests/unit/test_differ.py
uv run pytest tests/unit/test_differ.py::test_detect_column_rename -v
# Should FAIL

# 3. Implement minimal code (GREEN)
vim python/confiture/core/differ.py
uv run pytest tests/unit/test_differ.py::test_detect_column_rename -v
# Should PASS

# 4. Refactor (REFACTOR)
vim python/confiture/core/differ.py
uv run pytest tests/unit/test_differ.py -v
# All tests still pass

# 5. Quality checks (QA)
uv run ruff check .
uv run mypy python/confiture/
uv run pytest --cov=confiture

# 6. Commit (pre-commit hooks run automatically)
git add .
git commit -m "feat: detect column rename in schema diff"

# 7. Push and create PR
git push origin feature/schema-diff
```

---

## üé® Code Style

### Python Style Guide

Follow **PEP 8** with these additions:

```python
# Good: Descriptive names
def build_schema_from_ddl_files(env: str) -> str:
    """Build schema by concatenating DDL files for given environment."""
    ...

# Bad: Vague names
def build(e: str) -> str:
    ...

# Good: Type hints everywhere
def find_sql_files(self, directory: Path) -> list[Path]:
    return sorted(directory.rglob("*.sql"))

# Bad: No type hints
def find_sql_files(self, directory):
    return sorted(directory.rglob("*.sql"))

# Good: Docstrings (Google style)
def migrate_up(self, target: str | None = None) -> None:
    """Apply pending migrations up to target version.

    Args:
        target: Target migration version. If None, applies all pending.

    Raises:
        MigrationError: If migration fails.

    Example:
        >>> migrator = Migrator(env="production")
        >>> migrator.migrate_up(target="003_add_user_bio")
    """
    ...
```

### Formatting

```bash
# Auto-format with ruff
uv run ruff format .

# Check code
uv run ruff check .

# Type checking (using Astral's ty type checker)
uv run ty check python/confiture/
```

### Pre-commit Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.6.0
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
```

Note: Type checking is handled by Astral's `ty` in CI/CD (see quality-gate.yml).
For local type checking, run: `uv run ty check python/confiture/`

---

## üêõ Debugging

### pytest Debugging

```bash
# Run test with print statements
uv run pytest tests/unit/test_builder.py::test_find_sql_files -v -s

# Drop into debugger on failure
uv run pytest --pdb

# Run specific test with debugging
uv run pytest tests/unit/test_builder.py::test_find_sql_files --pdb -v
```

### Database Debugging

```bash
# Connect to test database
psql postgresql://localhost/confiture_test

# Check applied migrations
SELECT * FROM confiture_migrations ORDER BY applied_at DESC;

# Check schema version
SELECT * FROM confiture_version;
```

---

## üìù Documentation

### Docstring Format (Google Style)

```python
def build_schema(env: str, output_path: Path | None = None) -> str:
    """Build schema by concatenating DDL files for given environment.

    This function reads all SQL files from db/schema/ directory in
    deterministic order and concatenates them into a single schema file.

    Args:
        env: Environment name (e.g., "local", "production").
        output_path: Optional custom output path. If None, uses
            db/generated/schema_{env}.sql.

    Returns:
        Generated schema content as string.

    Raises:
        FileNotFoundError: If schema directory doesn't exist.
        ConfigurationError: If environment config is invalid.

    Example:
        >>> builder = SchemaBuilder(env="local")
        >>> schema = builder.build_schema("local")
        >>> print(len(schema))
        15234

    Note:
        Files are processed in alphabetical order. Use numbered
        directories (00_common/, 10_tables/) to control order.
    """
    ...
```

### README Updates

When adding features, update README.md:

```markdown
## Features

- ‚úÖ Build from DDL (Medium 1)
- ‚úÖ Incremental migrations (Medium 2)
- ‚úÖ Schema diff detection (NEW!)
- ‚è≥ Production sync (Medium 3) - Coming soon
- ‚è≥ Zero-downtime migrations (Medium 4) - Coming soon
```

---

## üîí Security

### Sensitive Data

**Never commit**:
- Database credentials (use environment variables)
- `.env` files
- Production data dumps
- API keys

**Always**:
- Use `psycopg3` parameterized queries (SQL injection prevention)
- Validate user input (file paths, environment names)
- Anonymize PII in production sync

```python
# Good: Parameterized query
cursor.execute(
    "SELECT * FROM users WHERE email = %s",
    (user_email,)
)

# Bad: String interpolation (SQL injection risk!)
cursor.execute(f"SELECT * FROM users WHERE email = '{user_email}'")
```

---

## ü§ù Contributing

### Branch Naming

```
feature/schema-diff          # New feature
fix/migration-rollback-bug   # Bug fix
docs/zero-downtime-guide     # Documentation
refactor/builder-cleanup     # Refactoring
test/integration-coverage    # Test improvements
```

### Commit Messages

Follow **Conventional Commits**:

```
feat: add schema diff detection
fix: correct column type mapping in differ
docs: update migration strategies guide
test: add integration tests for schema builder
refactor: simplify file discovery logic
perf: optimize hash computation for large files
```

### Pull Request Template

```markdown
## Description
Brief description of changes

## Type of Change
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change
- [ ] Documentation

## Checklist
- [x] Tests pass (`uv run pytest`)
- [x] Code formatted (`uv run ruff format`)
- [x] Type checking passes (`uv run ty check python/confiture/`)
- [x] Documentation updated
- [x] PHASES.md updated (if applicable)

## Testing
Describe testing performed

## Related Issues
Closes #123
```

---

## üéØ Current Status

### ‚úÖ Feature Complete (v0.5.0)

**Core Features**:
- ‚úÖ Schema builder (Medium 1) - Build from DDL in <1s
- ‚úÖ Migration system (Medium 2) - Incremental migrations with dry-run
- ‚úÖ Production sync (Medium 3) - Copy data with PII anonymization
- ‚úÖ Zero-downtime migrations (Medium 4) - Schema-to-schema via FDW
- ‚úÖ Schema diff detection
- ‚úÖ CLI with rich terminal output

**Enterprise Features**:
- ‚úÖ Distributed locking with advisory locks
- ‚úÖ Checksum verification for migration integrity
- ‚úÖ Transaction boundary control
- ‚úÖ Connection pooling with health checks
- ‚úÖ Schema validation and drift detection
- ‚úÖ Built-in observability (metrics, tracing)
- ‚úÖ Rollback safety with auto-generation

**Cloud Native**:
- ‚úÖ Kubernetes Helm charts
- ‚úÖ Health endpoints for probes
- ‚úÖ Graceful shutdown handling
- ‚úÖ CI/CD templates (GitHub Actions, GitLab, Jenkins, Argo CD)

**Advanced**:
- ‚úÖ Migration hooks with DAG execution
- ‚úÖ Custom anonymization strategies
- ‚úÖ Database schema linting (HIPAA, SOX, GDPR, PCI-DSS)
- ‚úÖ Risk assessment with downtime prediction
- ‚úÖ Blue-green migration orchestration
- ‚úÖ Large table patterns (batched operations)

**Quality Metrics**:
- **Test Coverage**: 3,200+ tests passing
- **Python Support**: 3.11, 3.12, 3.13
- **Documentation**: Comprehensive guides and API references
- **Rust Extension**: Optional 10-50x performance boost

---

## üö® Common Pitfalls

### ‚ùå Don't: Mix business logic with CLI
```python
# Bad: Business logic in CLI
@app.command()
def build(env: str):
    files = sorted(Path("db/schema").rglob("*.sql"))  # Logic in CLI!
    schema = "".join(f.read_text() for f in files)
```

### ‚úÖ Do: Separate concerns
```python
# Good: CLI calls core logic
@app.command()
def build(env: str):
    builder = SchemaBuilder(env=env)  # Core logic
    builder.build()                    # Delegate
```

---

### ‚ùå Don't: Skip type hints
```python
# Bad
def build_schema(env):
    return schema
```

### ‚úÖ Do: Add complete type hints
```python
# Good
def build_schema(env: str) -> str:
    return schema
```

---

### ‚ùå Don't: Use bare except
```python
# Bad
try:
    conn.execute(sql)
except:  # What error? Why?
    pass
```

### ‚úÖ Do: Catch specific exceptions
```python
# Good
try:
    conn.execute(sql)
except psycopg.OperationalError as e:
    raise MigrationError(f"Database connection failed: {e}") from e
```

---

## üìä Success Metrics

- ‚úÖ **Test Coverage**: 3,200+ tests passing
- ‚úÖ **Build Speed**: <1 second for fresh database builds
- ‚úÖ **CLI Commands**: 8 working (`build`, `migrate up/down`, `status`, `init`, `sync`, `schema-to-schema`)
- ‚úÖ **Documentation**: Comprehensive guides + API references
- ‚úÖ **Performance**: 10-50x faster with Rust extension
- ‚úÖ **Examples**: 5 production-ready scenarios
- ‚úÖ **CI/CD**: Multi-platform wheel building, quality gates, automated testing
- ‚úÖ **Python Support**: 3.11, 3.12, 3.13 tested and verified

---

## üÜò Getting Help

### Resources

- **Project Docs**: `docs/`
- **API Reference**: `docs/api/`
- **Examples**: `examples/`

### Questions to Ask

When stuck, ask:
1. "What test should I write first?" (RED)
2. "What's the simplest code to make this pass?" (GREEN)
3. "How can I improve this without breaking tests?" (REFACTOR)
4. "Does this meet quality standards?" (QA)

---

## üéâ Philosophy

> **"Make it work, make it right, make it fast - in that order."**

1. **Make it work**: Write failing test, minimal implementation
2. **Make it right**: Refactor, clean code, documentation
3. **Make it fast**: Optimize with Rust extension when needed

**Always follow TDD cycles. Always.**

---

**Last Updated**: January 2026
**Version**: 0.5.0 Feature Complete

---

*Making jam from strawberries, one commit at a time.* üçì‚ÜíüçØ
